{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9469d2f-7712-46e1-9425-367356fb0fda",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc3777d1-224f-4436-aac9-654bc97596e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a16efbc-8ca2-4cdb-824c-3db93c50c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "337222c3-9aad-48db-a549-7af3246d4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition   # used by a Node to decide whether to use a tool\n",
    "from langchain.agents import Tool # required to conver function to tool\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc45aa9c-3b11-4a27-8c5f-25b44b79c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a3602-2e38-4c13-84c9-d4903e15bfec",
   "metadata": {},
   "source": [
    "### Test LangChain OpenAi Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a53c7d-cd95-4845-8cca-481236bf9d59",
   "metadata": {},
   "source": [
    "OPENAI API USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0b24cdd-361e-4a8e-8392-c51bc41c7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an LLM instance\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# # Make a simple inference\n",
    "# user_prompt = \"\"\"\n",
    "# What is the capital of the US\n",
    "\n",
    "# \"\"\"\n",
    "# messages = [ HumanMessage(content=user_prompt), \n",
    "#              SystemMessage(content=\"Make sure to present your response in bullet point without markdown format\")\n",
    "#            ]\n",
    "\n",
    "# response = llm.invoke(messages)\n",
    "\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321db84-9010-4d3e-8fc6-0d33b0631eb4",
   "metadata": {},
   "source": [
    "GOOGLE GENERATIVE API USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b45a5785-d101-44c7-a078-ca5ed71f0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a653021-ec0d-46d3-94a1-a427012ddb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the US is **Washington, D.C.**\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What is the capital of the US\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [ HumanMessage(content=user_prompt), \n",
    "             SystemMessage(content=\"Make sure to present your response in bullet point without markdown format and extra character.\")\n",
    "           ]\n",
    "\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    google_api_key=gemini_api_key\n",
    ")\n",
    "\n",
    "print(google_llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27723fd-a852-4411-b8a5-c47b167851d4",
   "metadata": {},
   "source": [
    "### Assistant Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79d8d770-83dc-4ca0-8db3-f7740d849eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatorResponse(BaseModel):\n",
    "    feedback: str = Field(description=\"critical feedback on the assistant response\")\n",
    "    success_criteria_met: bool = Field(description=\"Whether the success criteria has been met\")# the users request\n",
    "    user_input_needed: bool = Field(description=\"True if more input is needed from the user for more clarity of the LLM get stucked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cac10bd6-03e8-4c4d-8e54-3a181d4bbc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = ChatGoogleGenerativeAI( model=\"gemini-2.5-flash\", \n",
    "                                       temperature=0, \n",
    "                                       google_api_key=gemini_api_key)\n",
    "\n",
    "evaluator_llm_with_output = evaluator_llm.with_structured_output(EvaluatorResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e8bcfae-ab60-4ff5-af0d-94a81eb441e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluatorResponse(feedback='The assistant should directly answer the question about the capital of the US.', success_criteria_met=False, user_input_needed=False, reason='The model did not answer the question directly.')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_llm_with_output.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb99673-f4a7-4c44-9b1d-d74547f967ba",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe866ef5-50e1-4e6b-8040-59babe524f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_Id</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Gender</th>\n",
       "      <th>city_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268408</td>\n",
       "      <td>02-01-1970</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269696</td>\n",
       "      <td>07-01-1970</td>\n",
       "      <td>F</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268159</td>\n",
       "      <td>08-01-1970</td>\n",
       "      <td>F</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270181</td>\n",
       "      <td>10-01-1970</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268073</td>\n",
       "      <td>11-01-1970</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_Id         DOB Gender  city_code\n",
       "0       268408  02-01-1970      M        4.0\n",
       "1       269696  07-01-1970      F        8.0\n",
       "2       268159  08-01-1970      F        8.0\n",
       "3       270181  10-01-1970      F        2.0\n",
       "4       268073  11-01-1970      M        1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Customer.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd435ee-8095-46c8-bec5-34c1558ab797",
   "metadata": {},
   "source": [
    "### Customised Tools (Node)\n",
    "\n",
    "This tool can be used as a node in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8110f7de-02dc-4f41-9922-e70d61071585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 5647 rows and 4 columns.\n",
      "\n",
      "Column Information:\n",
      "\n",
      "               dtype  missing_values  non_null_count\n",
      "customer_Id    int64               0            5647\n",
      "DOB           object               0            5647\n",
      "Gender        object               2            5645\n",
      "city_code    float64               2            5645\n",
      "\n",
      "\n",
      "Numeric Column Statistics:\n",
      "\n",
      "              count           mean          std       min       25%       50%       75%       max\n",
      "customer_Id  5647.0  271037.281034  2451.261711  266783.0  268912.0  271028.0  273180.0  275265.0\n",
      "city_code    5645.0       5.472631     2.859918       1.0       3.0       5.0       8.0      10.0\n",
      "\n",
      "\n",
      "Categorical Column Summary:\n",
      "\n",
      "       count unique         top  freq\n",
      "DOB     5647   4056  27-12-1988     7\n",
      "Gender  5645      2           M  2892\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_summary(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Returns a summary of the dataset including:\n",
    "    - Shape (rows, columns)\n",
    "    - Column names and data types\n",
    "    - Count of missing values per column\n",
    "    - Basic statistics for numeric columns\n",
    "    - Top unique values for categorical columns\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    summary = []\n",
    "    summary.append(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\\n\")\n",
    "\n",
    "    # Column info\n",
    "    col_info = pd.DataFrame({\n",
    "        \"dtype\": df.dtypes.astype(str),\n",
    "        \"missing_values\": df.isnull().sum(),\n",
    "        \"non_null_count\": df.notnull().sum()\n",
    "    })\n",
    "    summary.append(\"Column Information:\\n\")\n",
    "    summary.append(col_info.to_string())\n",
    "    summary.append(\"\\n\")\n",
    "\n",
    "    # Numeric stats\n",
    "    numeric_desc = df.describe(include=[float, int]).transpose()\n",
    "    summary.append(\"Numeric Column Statistics:\\n\")\n",
    "    summary.append(numeric_desc.to_string())\n",
    "    summary.append(\"\\n\")\n",
    "\n",
    "    # Categorical stats\n",
    "    cat_desc = df.describe(include=[object, \"category\"]).transpose()\n",
    "    if not cat_desc.empty:\n",
    "        summary.append(\"Categorical Column Summary:\\n\")\n",
    "        summary.append(cat_desc.to_string())\n",
    "        summary.append(\"\\n\")\n",
    "\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "\n",
    "print(data_summary(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcbaa484-0a53-4fe4-8a11-16b826e5ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_summary = Tool(name=\"summarize_data\", \n",
    "                    func=data_summary, \n",
    "                    description=\"Returns the summary of uploaded data including statistics for numerical and non-numerical fields.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ce59a-766f-4e75-8ae9-142c9eefd39f",
   "metadata": {},
   "source": [
    "### Agents and List of Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ea4f7ee-f653-4a9e-97ed-16d916e75711",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool_summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "322ad053-4b88-4b72-80e6-d80cbca13581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_llm =  ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    ")\n",
    "# bind tools to LLM\n",
    "google_llm__with_tools = google_llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73b3fa-f6ac-4ced-9589-ff8d0f5665e9",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443b548-51f4-431e-ba91-fe4398b5f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(state: State) -> Dict[str, Any]:\n",
    "    system_message = f\"\"\"\n",
    "            You are a data analyst assistant that can use tools to complete analysis tasks.\n",
    "            \n",
    "            You specialize in:\n",
    "            - Return summary of the dataset (Statistics, data description)\n",
    "            - Exploring datasets (especially CSV files provided by the user)\n",
    "            - Answering business or technical questions from the data\n",
    "            - Explaining insights clearly in plain language\n",
    "            - Asking clarifying questions if the task is ambiguous\n",
    "            \n",
    "            You keep working on a task until either:\n",
    "            1. You have a question or clarification for the user, OR\n",
    "            2. The success criteria is met.\n",
    "            \n",
    "            This is the success criteria:\n",
    "            {state['success_criteria']}\n",
    "\n",
    "            You should reply either with:\n",
    "            - A question for the user about this assignment (if more context or data is needed), OR\n",
    "            - Your final analysis/answer if you have enough information.\n",
    "            \n",
    "            If you have a question for the user, reply by clearly stating it. For example:\n",
    "            Question: please provide the CSV file containing sales data for analysis.\n",
    "            \n",
    "            If you have finished, reply only with the final analysis/answer â€” do not ask a question.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add rejection feedback (if any)\n",
    "    if state.get(\"feedback_on_work\"):\n",
    "        system_message += f\"\"\"\n",
    "            Previously, you thought you completed the assignment, but your reply was rejected because the success criteria was not met.\n",
    "            Here is the feedback on why this was rejected:\n",
    "            {state['feedback_on_work']}\n",
    "            With this feedback, please continue the assignment, ensuring that you meet the success criteria or ask a question to the user if \n",
    "            the data is missing.\n",
    "        \"\"\"\n",
    "    \n",
    "    found_system_message = False\n",
    "    messages = state[\"messages\"]\n",
    "    for message in messages:\n",
    "        if isinstance(message, SystemMessage):\n",
    "            message.content = system_message\n",
    "            found_system_message = True\n",
    "\n",
    "    # prepend system message if it does not already exists\n",
    "    if not found_system_message:\n",
    "        messages = [SystemMessage(content=system_message)] + messages\n",
    "    \n",
    "    # Invoke the LLM with tools\n",
    "    response = worker_llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Return updated state\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe01e3-b559-4116-beac-c8dccc3fe276",
   "metadata": {},
   "source": [
    "### State Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ac0a166-3681-4c9c-ac14-3a6172f9dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # blueprint for a dictionary with a list of any object. But here I paln to use dictionary since it is for llm\n",
    "    # something like {\"role\": \"user\", \"content\": \"Capital of Nig?\"}\n",
    "    # The messages uses the reducer. \n",
    "    # The others are simply values that we overwrite with any state change based on the evaluator LLM.\n",
    "    messages: Annotated[list, add_messages]\n",
    "    success_criteria: str\n",
    "    feedback_on_work: Optional[str]\n",
    "    success_criteria_met: bool\n",
    "    user_input_needed: bool\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "952bab04-4f59-4bb9-b0b0-474ce2d586a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476af97a-0d52-4071-beca-df79b69fc172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-(DA Assistant)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
