{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9469d2f-7712-46e1-9425-367356fb0fda",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc3777d1-224f-4436-aac9-654bc97596e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a16efbc-8ca2-4cdb-824c-3db93c50c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337222c3-9aad-48db-a549-7af3246d4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition   # used by a Node to decide whether to use a tool\n",
    "from langchain.agents import Tool # required to conver function to tool\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76d36c2-1185-4a1f-9b05-dbe6236fa2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc45aa9c-3b11-4a27-8c5f-25b44b79c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a3602-2e38-4c13-84c9-d4903e15bfec",
   "metadata": {},
   "source": [
    "### Test LangChain OpenAI Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a53c7d-cd95-4845-8cca-481236bf9d59",
   "metadata": {},
   "source": [
    "OPENAI API USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b24cdd-361e-4a8e-8392-c51bc41c7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an LLM instance\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# # Make a simple inference\n",
    "# user_prompt = \"\"\"\n",
    "# What is the capital of the US\n",
    "\n",
    "# \"\"\"\n",
    "# messages = [ HumanMessage(content=user_prompt), \n",
    "#              SystemMessage(content=\"Make sure to present your response in bullet point without markdown format\")\n",
    "#            ]\n",
    "\n",
    "# response = llm.invoke(messages)\n",
    "\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321db84-9010-4d3e-8fc6-0d33b0631eb4",
   "metadata": {},
   "source": [
    "---\n",
    "GOOGLE GENERATIVE API USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b45a5785-d101-44c7-a078-ca5ed71f0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a653021-ec0d-46d3-94a1-a427012ddb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of the United States is **Washington, D.C.**' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--065f077b-ce3b-4420-8e4b-2b993a7f5612-0' usage_metadata={'input_tokens': 11, 'output_tokens': 44, 'total_tokens': 55, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 30}}\n",
      "The capital of the United States is **Washington, D.C.**\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What is the capital of the US?\n",
    "\"\"\"\n",
    "\n",
    "messages = [ HumanMessage(content=user_prompt), \n",
    "             SystemMessage(content=\"Make sure to present your response in bullet point without markdown format and extra character.\")\n",
    "           ]\n",
    "\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    google_api_key=gemini_api_key\n",
    ")\n",
    "    \n",
    "response = google_llm.invoke(messages)\n",
    "print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf11d7e-2e8d-4c83-a106-6fefb51ae70c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa1bf1-0ae0-4337-a592-b2dc188abec0",
   "metadata": {},
   "source": [
    "GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b4df69a-1741-407c-98a2-8441edca39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key is explicitly imported from environment variable\n",
    "# groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450d8c14-8681-4c86-baf5-4f37a0eddff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='* The capital of the United States is Washington, D.C.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 59, 'total_tokens': 73, 'completion_time': 0.037263415, 'prompt_time': 0.003044755, 'queue_time': 0.092926418, 'total_time': 0.04030817}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--8c756ac1-528d-4e9a-a43d-81f26193f369-0' usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}\n",
      "* The capital of the United States is Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What is the capital of the US?\n",
    "\"\"\"\n",
    "\n",
    "messages = [ HumanMessage(content=user_prompt), \n",
    "             SystemMessage(content=\"Make sure to present your response in bullet point without markdown format and extra character.\")\n",
    "           ]\n",
    "\n",
    "groq_llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "response = groq_llm.invoke(messages)\n",
    "print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27723fd-a852-4411-b8a5-c47b167851d4",
   "metadata": {},
   "source": [
    "### Assistant Evaluator \n",
    "\n",
    "**Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d8d770-83dc-4ca0-8db3-f7740d849eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatorResponse(BaseModel):\n",
    "    feedback: str = Field(description=\"Critical feedback on the assistant response\")\n",
    "    success_criteria_met: bool = Field(description=\"Whether the success criteria has been met\") # the users request is the criteria\n",
    "    user_input_needed: bool = Field(description=\"True if more input is needed from the user for more clarity of the LLM get stucked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da69bb-afc4-441f-85f2-8f4acbf30371",
   "metadata": {},
   "source": [
    "Gemini Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac10bd6-03e8-4c4d-8e54-3a181d4bbc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = ChatGoogleGenerativeAI( model=\"gemini-2.5-flash\", \n",
    "                                       temperature=0, \n",
    "                                       google_api_key=gemini_api_key)\n",
    "\n",
    "evaluator_llm_with_output = evaluator_llm.with_structured_output(EvaluatorResponse)\n",
    "\n",
    "response = evaluator_llm_with_output.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed42508b-0ca2-46ef-91e2-d6d24131710e",
   "metadata": {},
   "source": [
    "Groq Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e8bcfae-ab60-4ff5-af0d-94a81eb441e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedback='The assistant should have answered that the capital of the US is Washington, D.C.' success_criteria_met=False user_input_needed=False\n"
     ]
    }
   ],
   "source": [
    "evaluator_llm_with_output = groq_llm.with_structured_output(EvaluatorResponse)\n",
    "\n",
    "response = evaluator_llm_with_output.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb99673-f4a7-4c44-9b1d-d74547f967ba",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe866ef5-50e1-4e6b-8040-59babe524f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    df = pd.read_csv(\"Customer.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aee8802-efae-4db4-a632-6f3fd26a4c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_Id</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Gender</th>\n",
       "      <th>city_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268408</td>\n",
       "      <td>02-01-1970</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269696</td>\n",
       "      <td>07-01-1970</td>\n",
       "      <td>F</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268159</td>\n",
       "      <td>08-01-1970</td>\n",
       "      <td>F</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270181</td>\n",
       "      <td>10-01-1970</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268073</td>\n",
       "      <td>11-01-1970</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_Id         DOB Gender  city_code\n",
       "0       268408  02-01-1970      M        4.0\n",
       "1       269696  07-01-1970      F        8.0\n",
       "2       268159  08-01-1970      F        8.0\n",
       "3       270181  10-01-1970      F        2.0\n",
       "4       268073  11-01-1970      M        1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7348fe89-aa69-4661-8e7c-4d0d79ad4387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5647 entries, 0 to 5646\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   customer_Id  5647 non-null   int64  \n",
      " 1   DOB          5647 non-null   object \n",
      " 2   Gender       5645 non-null   object \n",
      " 3   city_code    5645 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 176.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db549e-9fb6-4401-8138-20473e352d1d",
   "metadata": {},
   "source": [
    "----\n",
    "### State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ae833a8-e3d8-428f-90e8-ec6b85f93731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    success_criteria: str\n",
    "    feedback_on_assist: Optional[str]\n",
    "    success_criteria_met: bool\n",
    "    user_input_needed: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b737f-808e-48c2-a43c-758268c7b1b4",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55712d87-550a-4aee-a1ac-5402bb867be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data = {\"df\": None}\n",
    "\n",
    "def load_csv(file):\n",
    "    \"\"\"\n",
    "    Loads a CSV file into shared_data['df'] and returns a status message.\n",
    "    \"\"\"\n",
    "    if file is None:\n",
    "        return \"âš ï¸ No file uploaded yet.\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file.name if hasattr(file, \"name\") else file)\n",
    "        shared_data[\"df\"] = df\n",
    "\n",
    "        nrows, ncols = df.shape\n",
    "        response_message = (\n",
    "            f\"âœ… CSV loaded successfully! \"\n",
    "            f\"Your dataset has {nrows} rows and {ncols} columns.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        response_message = f\"âŒ Error reading CSV: {e}\"\n",
    "\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69e499-8b44-4b4e-af1a-74ed16d52ae0",
   "metadata": {},
   "source": [
    "### Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0ccb054-7ed9-43e7-9cd1-39321b0cdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_data_summary(state: State) -> str:\n",
    "    \"\"\"\n",
    "    Returns a summary of the dataset including:\n",
    "    - Shape (rows, columns)\n",
    "    - Column names and data types\n",
    "    - Count of missing values per column\n",
    "    - Basic statistics for numeric columns\n",
    "    - Top unique values for categorical columns\n",
    "    \"\"\"\n",
    "    df = shared_data['df']\n",
    "    \n",
    "    summary = [\"summary of dataframe:\"]\n",
    "    summary.append(f\"\\n\\nDataset contains {df.shape[0]} rows and {df.shape[1]} columns.\\n\")\n",
    "\n",
    "    # Column info\n",
    "    col_info = pd.DataFrame({\n",
    "        \"dtype\": df.dtypes.astype(str),\n",
    "        \"missing_values\": df.isnull().sum(),\n",
    "        \"non_null_count\": df.notnull().sum()\n",
    "    })\n",
    "    summary.append(\"Column Information:\\n\")\n",
    "    summary.append(col_info.to_string())\n",
    "    summary.append(\"\\n\")\n",
    "\n",
    "    # Numeric stats\n",
    "    numeric_desc = df.describe(include=[float, int]).transpose()\n",
    "    summary.append(\"Numeric Column Statistics:\\n\")\n",
    "    summary.append(numeric_desc.to_string())\n",
    "    summary.append(\"\\n\")\n",
    "\n",
    "    # Categorical stats\n",
    "    cat_desc = df.describe(include=[object, \"category\"]).transpose()\n",
    "    if not cat_desc.empty:\n",
    "        summary.append(\"Categorical Column Summary:\\n\")\n",
    "        summary.append(cat_desc.to_string())\n",
    "        summary.append(\"\\n\")\n",
    "\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "\n",
    "tool_summary = Tool(name=\"summarize_data\", \n",
    "                    func=tool_data_summary, \n",
    "                    description=f\"Returns the shape and summary of an existing dataframe {shared_data['df']} including numerical and non-numerical fields. Use this tool when the user asks for a data summary.\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ed4e9-6027-4d9c-920c-9a1128553d40",
   "metadata": {},
   "source": [
    "**Merge Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7ed22-6df4-467d-a07e-b7a969c01796",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool_summary]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2174658-ad72-4586-99b7-42b32c08340f",
   "metadata": {},
   "source": [
    "**Bind Tools to LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf0d2d2b-d6e7-41e1-81fa-35956337ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llm_with_tools = groq_llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b99de7-80ba-4d09-9345-272b27c245a5",
   "metadata": {},
   "source": [
    "### Evaluate Tools Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47269cb7-f830-46f6-98eb-a968fd460285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec80e0bf-9938-4fe5-932b-80b2a7a28d9b",
   "metadata": {},
   "source": [
    "### Graph, Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b38c6ec-118e-42eb-bd23-0a171dc6d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decides_if_tool(state: State):\n",
    "    \"\"\"\n",
    "    The agent's output is an AIMessage that contains a tool_call object\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae81a8af-b9c2-484d-82ac-fc3fec7117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state: State):\n",
    "    return {\"messages\": [groq_llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node('agent', assistant)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "\n",
    "graph_builder.add_edge(START, \"agent\")\n",
    "graph_builder.add_conditional_edges(\"agent\", decides_if_tool, {\"tools\":\"tools\", \"end\": END})\n",
    "graph_builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = graph_builder.compile() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4c0ee92-a81c-4ab1-b3b1-b909e53dae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nest_asyncio\n",
    "# import pyppeteer\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png(draw_method='pyppeteer')))\n",
    "# # # await graph.get_graph().draw_mermaid_png(output_file_path=\"graph.png\", draw_method=MermaidDrawMethod.PYPPETEER )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6455dbe-a7d0-4237-ba18-3dd26d21e7e2",
   "metadata": {},
   "source": [
    "### Gradio Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33bfa967-2994-4d94-a0b3-fb5a7fc714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='48247df1-c671-4ab2-8556-eb21f097b53c'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'a34aym4rg', 'function': {'arguments': '{\"__arg1\":\"customer_data\"}', 'name': 'summarize_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 763, 'total_tokens': 782, 'completion_time': 0.044935466, 'prompt_time': 0.063135933, 'queue_time': 0.085568316, 'total_time': 0.108071399}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0f35dffd-d0d7-4324-a817-57b2db110b69-0', tool_calls=[{'name': 'summarize_data', 'args': {'__arg1': 'customer_data'}, 'id': 'a34aym4rg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 763, 'output_tokens': 19, 'total_tokens': 782}), ToolMessage(content='summary of dataframe:\\n\\n\\nDataset contains 5647 rows and 4 columns.\\n\\nColumn Information:\\n\\n               dtype  missing_values  non_null_count\\ncustomer_Id    int64               0            5647\\nDOB           object               0            5647\\nGender        object               2            5645\\ncity_code    float64               2            5645\\n\\n\\nNumeric Column Statistics:\\n\\n              count           mean          std       min       25%       50%       75%       max\\ncustomer_Id  5647.0  271037.281034  2451.261711  266783.0  268912.0  271028.0  273180.0  275265.0\\ncity_code    5645.0       5.472631     2.859918       1.0       3.0       5.0       8.0      10.0\\n\\n\\nCategorical Column Summary:\\n\\n       count unique         top  freq\\nDOB     5647   4056  27-12-1988     7\\nGender  5645      2           M  2892\\n\\n', name='summarize_data', id='e5ab40a5-c6ea-4ae1-8f9d-62fed0c80b3a', tool_call_id='a34aym4rg'), AIMessage(content=\"The data contains 5647 rows and 4 columns. The columns are customer_Id, DOB, Gender, and city_code. The customer_Id column has a mean of 271037.28 and a standard deviation of 2451.26. The city_code column has a mean of 5.47 and a standard deviation of 2.86. The DOB column has 4056 unique dates, with the most frequent date being 27-12-1988. The Gender column has 2 unique values, with 'M' being the most frequent.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 1043, 'total_tokens': 1160, 'completion_time': 0.271756546, 'prompt_time': 0.086586104, 'queue_time': 0.084615323, 'total_time': 0.35834265}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ae7dc131-c7a2-4dec-b3b7-389192b6917e-0', usage_metadata={'input_tokens': 1043, 'output_tokens': 117, 'total_tokens': 1160})]}\n",
      "{'messages': [HumanMessage(content='than you for you response', additional_kwargs={}, response_metadata={}, id='f0b2e309-f152-4f15-8f71-a50bb9aee5cd'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'ek7v2d5vx', 'function': {'arguments': '{\"__arg1\":\"customer_data\"}', 'name': 'summarize_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 767, 'total_tokens': 786, 'completion_time': 0.051660632, 'prompt_time': 0.063142577, 'queue_time': 0.08453286, 'total_time': 0.114803209}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5ec1a9c6-ce4a-41d8-949c-da8dcc244383-0', tool_calls=[{'name': 'summarize_data', 'args': {'__arg1': 'customer_data'}, 'id': 'ek7v2d5vx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 767, 'output_tokens': 19, 'total_tokens': 786}), ToolMessage(content='summary of dataframe:\\n\\n\\nDataset contains 5647 rows and 4 columns.\\n\\nColumn Information:\\n\\n               dtype  missing_values  non_null_count\\ncustomer_Id    int64               0            5647\\nDOB           object               0            5647\\nGender        object               2            5645\\ncity_code    float64               2            5645\\n\\n\\nNumeric Column Statistics:\\n\\n              count           mean          std       min       25%       50%       75%       max\\ncustomer_Id  5647.0  271037.281034  2451.261711  266783.0  268912.0  271028.0  273180.0  275265.0\\ncity_code    5645.0       5.472631     2.859918       1.0       3.0       5.0       8.0      10.0\\n\\n\\nCategorical Column Summary:\\n\\n       count unique         top  freq\\nDOB     5647   4056  27-12-1988     7\\nGender  5645      2           M  2892\\n\\n', name='summarize_data', id='c7e6381c-4a6a-4715-9e4f-fccb831404c3', tool_call_id='ek7v2d5vx'), AIMessage(content=\"I hope this summary helps you understand the dataset better. Let me know if you have any further questions or if there's anything else I can help you with.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 1047, 'total_tokens': 1080, 'completion_time': 0.093352156, 'prompt_time': 0.085774103, 'queue_time': 0.084748574, 'total_time': 0.179126259}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--bc9ad85d-78be-4af7-b1cb-fb9bb5cbaab2-0', usage_metadata={'input_tokens': 1047, 'output_tokens': 33, 'total_tokens': 1080})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 745, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1621, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 554, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 944, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14756\\1605755339.py\", line 3, in chat\n",
      "    result = graph.invoke({\"messages\": message}) # last state\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py\", line 3026, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\DELL\\Desktop\\New-Era-Projects\\Data-Analyst-Assistant-App\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py\", line 2675, in stream\n",
      "    raise GraphRecursionError(msg)\n",
      "langgraph.errors.GraphRecursionError: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='thank you', additional_kwargs={}, response_metadata={}, id='0124a45a-69ba-48af-a487-e27d0aa6ee3b'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'g0dcznpq3', 'function': {'arguments': '{\"__arg1\":\"customer data\"}', 'name': 'summarize_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 764, 'total_tokens': 783, 'completion_time': 0.051558027, 'prompt_time': 0.064522239, 'queue_time': 0.086264962, 'total_time': 0.116080266}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--186ff850-3408-4b6b-864f-4091e96f9896-0', tool_calls=[{'name': 'summarize_data', 'args': {'__arg1': 'customer data'}, 'id': 'g0dcznpq3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 764, 'output_tokens': 19, 'total_tokens': 783}), ToolMessage(content='summary of dataframe:\\n\\n\\nDataset contains 5647 rows and 4 columns.\\n\\nColumn Information:\\n\\n               dtype  missing_values  non_null_count\\ncustomer_Id    int64               0            5647\\nDOB           object               0            5647\\nGender        object               2            5645\\ncity_code    float64               2            5645\\n\\n\\nNumeric Column Statistics:\\n\\n              count           mean          std       min       25%       50%       75%       max\\ncustomer_Id  5647.0  271037.281034  2451.261711  266783.0  268912.0  271028.0  273180.0  275265.0\\ncity_code    5645.0       5.472631     2.859918       1.0       3.0       5.0       8.0      10.0\\n\\n\\nCategorical Column Summary:\\n\\n       count unique         top  freq\\nDOB     5647   4056  27-12-1988     7\\nGender  5645      2           M  2892\\n\\n', name='summarize_data', id='f3d17e46-f568-421c-a632-3997fe46420f', tool_call_id='g0dcznpq3'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'nj630bdf3', 'function': {'arguments': '{\"__arg1\":\"customer data\"}', 'name': 'summarize_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1044, 'total_tokens': 1063, 'completion_time': 0.028676628, 'prompt_time': 0.085479746, 'queue_time': 0.086169049, 'total_time': 0.114156374}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--fe053a22-acd7-45d3-a080-a3c4b839ac9f-0', tool_calls=[{'name': 'summarize_data', 'args': {'__arg1': 'customer data'}, 'id': 'nj630bdf3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1044, 'output_tokens': 19, 'total_tokens': 1063}), ToolMessage(content='summary of dataframe:\\n\\n\\nDataset contains 5647 rows and 4 columns.\\n\\nColumn Information:\\n\\n               dtype  missing_values  non_null_count\\ncustomer_Id    int64               0            5647\\nDOB           object               0            5647\\nGender        object               2            5645\\ncity_code    float64               2            5645\\n\\n\\nNumeric Column Statistics:\\n\\n              count           mean          std       min       25%       50%       75%       max\\ncustomer_Id  5647.0  271037.281034  2451.261711  266783.0  268912.0  271028.0  273180.0  275265.0\\ncity_code    5645.0       5.472631     2.859918       1.0       3.0       5.0       8.0      10.0\\n\\n\\nCategorical Column Summary:\\n\\n       count unique         top  freq\\nDOB     5647   4056  27-12-1988     7\\nGender  5645      2           M  2892\\n\\n', name='summarize_data', id='e4420216-1781-4156-83de-aa1e044cf6b2', tool_call_id='nj630bdf3'), AIMessage(content='The provided data summary includes information about the dataset, such as the number of rows and columns, data types, and missing values. It also provides statistics for numerical columns (customer_Id and city_code) and a summary for categorical columns (DOB and Gender).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 1324, 'total_tokens': 1376, 'completion_time': 0.169265212, 'prompt_time': 0.108749924, 'queue_time': 0.087380817, 'total_time': 0.278015136}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--8536a77e-811a-4fde-b5bb-cd9d1ccd7b15-0', usage_metadata={'input_tokens': 1324, 'output_tokens': 52, 'total_tokens': 1376})]}\n",
      "{'messages': [HumanMessage(content='Thank you. I would like to know if different genders that are there in the result of the summarzed dataset', additional_kwargs={}, response_metadata={}, id='ded59a94-face-4aac-a5c1-9b74f3acccfb'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'yy9x5byzh', 'function': {'arguments': '{\"__arg1\":\"Gender\"}', 'name': 'summarize_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 784, 'total_tokens': 802, 'completion_time': 0.058176237, 'prompt_time': 0.064973423, 'queue_time': 0.084559198, 'total_time': 0.12314966}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--301f5845-df91-479d-8fa2-6e73fd56eb17-0', tool_calls=[{'name': 'summarize_data', 'args': {'__arg1': 'Gender'}, 'id': 'yy9x5byzh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 784, 'output_tokens': 18, 'total_tokens': 802}), ToolMessage(content='summary of dataframe:\\n\\n\\nDataset contains 5647 rows and 4 columns.\\n\\nColumn Information:\\n\\n               dtype  missing_values  non_null_count\\ncustomer_Id    int64               0            5647\\nDOB           object               0            5647\\nGender        object               2            5645\\ncity_code    float64               2            5645\\n\\n\\nNumeric Column Statistics:\\n\\n              count           mean          std       min       25%       50%       75%       max\\ncustomer_Id  5647.0  271037.281034  2451.261711  266783.0  268912.0  271028.0  273180.0  275265.0\\ncity_code    5645.0       5.472631     2.859918       1.0       3.0       5.0       8.0      10.0\\n\\n\\nCategorical Column Summary:\\n\\n       count unique         top  freq\\nDOB     5647   4056  27-12-1988     7\\nGender  5645      2           M  2892\\n\\n', name='summarize_data', id='8fb4ecca-1390-4b24-8f67-065c7f290971', tool_call_id='yy9x5byzh'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'zmm0t60yh', 'function': {'arguments': '{\"__arg1\":\"Gender\"}', 'name': 'summarize_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1063, 'total_tokens': 1119, 'completion_time': 0.141187137, 'prompt_time': 0.087147285, 'queue_time': 0.085185792, 'total_time': 0.228334422}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--fe6e8e7e-9440-4b42-b20b-3c34edd823f9-0', tool_calls=[{'name': 'summarize_data', 'args': {'__arg1': 'Gender'}, 'id': 'zmm0t60yh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1063, 'output_tokens': 56, 'total_tokens': 1119}), ToolMessage(content='summary of dataframe:\\n\\n\\nDataset contains 5647 rows and 4 columns.\\n\\nColumn Information:\\n\\n               dtype  missing_values  non_null_count\\ncustomer_Id    int64               0            5647\\nDOB           object               0            5647\\nGender        object               2            5645\\ncity_code    float64               2            5645\\n\\n\\nNumeric Column Statistics:\\n\\n              count           mean          std       min       25%       50%       75%       max\\ncustomer_Id  5647.0  271037.281034  2451.261711  266783.0  268912.0  271028.0  273180.0  275265.0\\ncity_code    5645.0       5.472631     2.859918       1.0       3.0       5.0       8.0      10.0\\n\\n\\nCategorical Column Summary:\\n\\n       count unique         top  freq\\nDOB     5647   4056  27-12-1988     7\\nGender  5645      2           M  2892\\n\\n', name='summarize_data', id='a3cd61ad-7d5f-46c7-b462-71dc502b4f68', tool_call_id='zmm0t60yh'), AIMessage(content='There are 2 unique genders in the dataset: M (Male) and F (Female). The frequency of each gender is as follows:\\n\\n- Male: 2892\\n- Female: 2753 \\n\\nNote: The frequency of each gender may not add up to the total number of rows in the dataset due to missing values.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 1342, 'total_tokens': 1410, 'completion_time': 0.18479888, 'prompt_time': 0.107619441, 'queue_time': 0.084835552, 'total_time': 0.292418321}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9b540c84-5876-4e8f-ad52-14ccf3ebdf63-0', usage_metadata={'input_tokens': 1342, 'output_tokens': 68, 'total_tokens': 1410})]}\n"
     ]
    }
   ],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = [HumanMessage(content=user_input)]\n",
    "    result = graph.invoke({\"messages\": message}) # last state\n",
    "    print(result)\n",
    "    return result[\"messages\"][-1].content  # the content of the AIMessage\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸ“Š Data Analyst Assistant\")\n",
    "    gr.Markdown(\"Upload a CSV file and then chat with the assistant.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        csv_input = gr.File(label=\"Upload CSV\", file_types=[\".csv\"])\n",
    "        csv_output = gr.Textbox(label=\"Upload Status\", interactive=False)\n",
    "\n",
    "    csv_input.change(fn=load_csv, inputs=csv_input, outputs=csv_output)\n",
    "\n",
    "    gr.ChatInterface(fn=chat, type=\"messages\")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1820b-c4dc-4118-8057-af3539792848",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73b3fa-f6ac-4ced-9589-ff8d0f5665e9",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c443b548-51f4-431e-ba91-fe4398b5f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Worker function that manages system instructions and invokes the LLM with tools.\n",
    "\n",
    "    This function ensures the assistant always has an up-to-date system message\n",
    "    guiding its behavior (e.g., role, success criteria, or feedback from prior attempts).\n",
    "    It updates or prepends a SystemMessage to the conversation history, sends the\n",
    "    updated messages to the LLM, and returns the assistant's latest response.\n",
    "\n",
    "    Workflow:\n",
    "        1. Construct a dynamic system message based on:\n",
    "            - The success criteria from state\n",
    "            - Optional feedback on previous work\n",
    "        2. Check if a SystemMessage already exists in state[\"messages\"]:\n",
    "            - If yes, update its content with the new system message\n",
    "            - If no, prepend a new SystemMessage to the messages list\n",
    "        3. Invoke the LLM (with tools enabled) on the updated message history\n",
    "        4. Return the new assistant response so it can be merged into state\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state containing conversation history, \n",
    "                       success criteria, and optional feedback.\n",
    "\n",
    "    Returns:\n",
    "        dict: A partial state update containing:\n",
    "            - \"messages\": A list with the assistant's latest response message.\n",
    "    \"\"\"\n",
    "    system_message = f\"\"\"\n",
    "        You are a data analyst assistant that collaborates with tools to complete analysis tasks. \n",
    "        Your role is to:\n",
    "        - Present results from tools clearly and accurately to the user\n",
    "        - Provide context, explanations, or next steps if helpful\n",
    "        - Ask the user clarifying questions if needed\n",
    "        - Stop once the success criteria is met\n",
    "        \n",
    "        The success criteria for this task is:\n",
    "        {state['success_criteria']}\n",
    "        \n",
    "        If a tool has returned an analysis, include that result in your reply rather than repeating the analysis yourself.\n",
    "        If the task is incomplete or ambiguous, ask a clear question to the user.\n",
    "        If the task is complete, present the final analysis/answer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add rejection feedback (if any)\n",
    "    if state.get(\"feedback_on_assist\"):\n",
    "        system_message += f\"\"\"\n",
    "            Previously, you thought you completed the assignment, but your reply was rejected because the success criteria was not met.\n",
    "            Here is the feedback on why this was rejected:\n",
    "            {state['feedback_on_assist']}\n",
    "            With this feedback, please continue the assignment, ensuring that you meet the success criteria or ask a question to the user if \n",
    "            the data is missing.\n",
    "        \"\"\"\n",
    "    \n",
    "    found_system_message = False\n",
    "    messages = state[\"messages\"]\n",
    "    for message in messages:\n",
    "        if isinstance(message, SystemMessage):\n",
    "            message.content = system_message\n",
    "            found_system_message = True\n",
    "\n",
    "    # prepend system message if it does not already exists\n",
    "    if not found_system_message:\n",
    "        messages = [SystemMessage(content=system_message)] + messages\n",
    "    \n",
    "    response = google_llm__with_tools.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1bb1477-e33d-4909-9c71-b7f8abe6451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decides_if_tool(state: State):\n",
    "    \"\"\"\n",
    "    Router function that decides the next node in the graph \n",
    "    based on the assistant's most recent message.\n",
    "\n",
    "    The function inspects the last message in the conversation:\n",
    "      - If the message contains a tool call, the flow should continue \n",
    "        to the \"tools\" node for execution.\n",
    "      - Otherwise, the flow proceeds to the \"evaluator\" node to \n",
    "        check if the assistant's response meets the success criteria.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state containing the conversation \n",
    "                       history and other workflow metadata.\n",
    "  \n",
    "    Returns:\n",
    "        str: The label of the next node to route to.\n",
    "             - \"tools\" if the last message requests a tool call\n",
    "             - \"evaluator\" if no tool call is present\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"evaluator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcd7de56-a662-4fa8-9ae4-7132650bbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation(messages: List[Any]) -> str:\n",
    "    conversation = \"Conversation history:\\n\\n\"\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            conversation += f\"User: {message.content}\\n\"\n",
    "        elif isinstance(message, AIMessage):\n",
    "            text = message.content or \"[Tools use]\"\n",
    "            conversation += f\"Assistant: {text}\\n\"\n",
    "    return conversation\n",
    "\n",
    "\n",
    "def evaluator(state: State) -> State:\n",
    "    last_response = state[\"messages\"][-1].content\n",
    "\n",
    "    system_message = \"\"\"\n",
    "        You are an evaluator that determines if a task has been completed successfully by an Assistant.\n",
    "        Assess the Assistant's last response based on the given criteria. Respond with your feedback, and with your decision on whether \n",
    "        the success criteria has been met, and whether more input is needed from the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_message = f\"\"\"\n",
    "        You are evaluating a conversation between the User and Assistant. You decide what action to take based on the last response from the Assistant.\n",
    "\n",
    "        The entire conversation with the assistant, with the user's original request and all replies, is:\n",
    "        {format_conversation(state['messages'])} \n",
    "        \n",
    "        The success criteria for this assignment is:\n",
    "        {state['success_criteria']}\n",
    "        \n",
    "        And the final response from the Assistant that you are evaluating is:\n",
    "        {last_response}\n",
    "        \n",
    "        Respond with your feedback, and decide if the success criteria is met by this response.\n",
    "        Also, decide if more user input is required, either because the assistant has a question, needs clarification, or seems to be stuck and \n",
    "        unable to answer without help.\n",
    "    \"\"\"\n",
    "    if state[\"feedback_on_assist\"]:\n",
    "        user_message += f\"Also, note that in a prior attempt from the Assistant, you provided this feedback: {state['feedback_on_assist']}\\n\"\n",
    "        user_message += \"If you're seeing the Assistant repeating the same mistakes, then consider responding that user input is required.\"\n",
    "    \n",
    "    evaluator_messages = [SystemMessage(content=system_message), HumanMessage(content=user_message)]\n",
    "\n",
    "    eval_result = evaluator_llm_with_output.invoke(evaluator_messages)\n",
    "    \n",
    "    new_state = {\n",
    "        \"messages\": [AIMessage(content=f\"Evaluator Feedback on this answer: {eval_result.feedback}\")],\n",
    "        \"feedback_on_assist\": eval_result.feedback,\n",
    "        \"success_criteria_met\": eval_result.success_criteria_met,\n",
    "        \"user_input_needed\": eval_result.user_input_needed \n",
    "    }\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7132699a-f767-41ef-b3df-77444c558095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decides_based_on_evaluation(state: State) -> str:\n",
    "    if state[\"success_criteria_met\"] or state[\"user_input_needed\"]:\n",
    "        return \"END\"\n",
    "    else:\n",
    "        return \"assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe01e3-b559-4116-beac-c8dccc3fe276",
   "metadata": {},
   "source": [
    "### Build Graph\n",
    "* Connect nodes\n",
    "* Compile the graph with memory saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "952bab04-4f59-4bb9-b0b0-474ce2d586a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ac0a166-3681-4c9c-ac14-3a6172f9dce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1fb4668fd10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"assistant\", assistant)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "graph_builder.add_node(\"evaluator\", evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "476af97a-0d52-4071-beca-df79b69fc172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1fb4668fd10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"assistant\")\n",
    "graph_builder.add_conditional_edges(\"assistant\", decides_if_tool, {\"tools\": \"tools\", \"evaluator\": \"evaluator\"})\n",
    "graph_builder.add_edge(\"tools\", \"assistant\")\n",
    "graph_builder.add_conditional_edges(\"evaluator\", decides_based_on_evaluation, {\"assistant\": \"assistant\", \"END\": END})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a99ec3-82dd-4c5e-8a35-77d1ffb1943f",
   "metadata": {},
   "source": [
    "**Compile the nodes and edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0b281ec-06be-46f7-a83b-0a7c55f9255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = {\"thread_id\": None}\n",
    "\n",
    "def get_thread_id():\n",
    "    if session_data[\"thread_id\"] is None:\n",
    "        session_data[\"thread_id\"] = str(uuid.uuid4())  \n",
    "    return session_data[\"thread_id\"]\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1932c2c8-ec9c-47ac-84a1-a26622ea8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37c55be2-2d92-4e88-9df5-4a5f77daa669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a377d7-2211-4851-9e00-dc62ae509d10",
   "metadata": {},
   "source": [
    "### Gradio App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30267b4f-a448-4400-9093-0568a37ae356",
   "metadata": {},
   "source": [
    "**Data Handler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95535e37-dc61-4214-b7c2-d0eadb41ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data = {\"df\": None}\n",
    "\n",
    "def load_csv(file):\n",
    "    \"\"\"\n",
    "    Loads a CSV file into shared_data['df'] and returns a status message.\n",
    "    \"\"\"\n",
    "    if file is None:\n",
    "        return \"âš ï¸ No file uploaded yet.\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file.name if hasattr(file, \"name\") else file)\n",
    "        shared_data[\"df\"] = df\n",
    "\n",
    "        nrows, ncols = df.shape\n",
    "        response_message = (\n",
    "            f\"âœ… CSV loaded successfully! \"\n",
    "            f\"Your dataset has {nrows} rows and {ncols} columns.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        response_message = f\"âŒ Error reading CSV: {e}\"\n",
    "\n",
    "    return response_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaeaa0b-cbc7-46f3-857d-2faee0aa2fbc",
   "metadata": {},
   "source": [
    "**Chat Han**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75058904-6767-461e-bee7-fc4adba8db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_assistant(user_input, history):\n",
    "    if shared_data[\"df\"] is None:\n",
    "        return \"Please upload a CSV file first.\"\n",
    "    \n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=user_input)],\n",
    "        \"success_criteria\": \"Provide insights based on the uploaded CSV dataset.\",\n",
    "        \"feedback_on_assist\": None,\n",
    "        \"success_criteria_met\": False,\n",
    "        \"user_input_needed\": False\n",
    "    }\n",
    "\n",
    "    thread_id =  get_thread_id()\n",
    "    result = graph.invoke(state, config={\"configurable\": {\"thread_id\": thread_id}})\n",
    "\n",
    "    print(result)\n",
    "    # Get last assistant message safely\n",
    "    last_msg = result[\"messages\"][-1]\n",
    "    return getattr(last_msg, \"content\", str(last_msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b892863-a7f8-4036-af78-5584d7a27154",
   "metadata": {},
   "source": [
    "**Application Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "372b9df3-d9b2-4364-9d5a-4f2d6dd0e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸ“Š Data Analyst Assistant\")\n",
    "    gr.Markdown(\"Upload a CSV file and then chat with the assistant.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        csv_input = gr.File(label=\"Upload CSV\", file_types=[\".csv\"])\n",
    "        csv_output = gr.Textbox(label=\"Upload Status\", interactive=False)\n",
    "\n",
    "    csv_input.change(fn=load_csv, inputs=csv_input, outputs=csv_output)\n",
    "\n",
    "    gr.ChatInterface(fn=chat_with_assistant, type=\"messages\")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99b105ad-65c9-4954-bac8-70c9d033ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='summarize the dataset', additional_kwargs={}, response_metadata={}), {'role': 'assistant', 'content': 'Dataset contains 3 rows and 2 columns.\\n\\nColumn Information:\\n\\n    dtype  missing_values  non_null_count\\na   int64               0               3\\nb  object               0               3\\n\\n\\nNumeric Column Statistics:\\n\\n   count  mean  std  min  25%  50%  75%  max\\na    3.0   2.0  1.0  1.0  1.5  2.0  2.5  3.0\\n\\n\\nCategorical Column Summary:\\n\\n  count unique top freq\\nb     3      3   x    1\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"a\": [1,2,3], \"b\": [\"x\",\"y\",\"z\"]})\n",
    "shared_data[\"df\"] = df\n",
    "state = {\"messages\": [HumanMessage(content=\"summarize the dataset\")]}\n",
    "print(tool_data_summary(state)[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00c286-8e40-4be3-b471-146bbdd942be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-(DA Assistant)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
